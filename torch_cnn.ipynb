{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image Classification using CNN from Scratch in Pytorch\n",
    "https://youtu.be/9OHlgDjaE2I"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision, pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU Check\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Transformers\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)), # make images 150*150 px\n",
    "    transforms.RandomHorizontalFlip(), # add variation and increase number of unique images\n",
    "    transforms.ToTensor(), # 0-255 to 0-1, also converts from numpy to tensor\n",
    "    transforms.Normalize(\n",
    "        [0.5,0.5,0.5],\n",
    "        [0.5,0.5,0.5]\n",
    "    )\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training Data: 14034, Testing Data: 3000\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "\n",
    "train_path = \"./archive/seg_train/seg_train\"\n",
    "test_path = \"./archive/seg_test/seg_test\"\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,\n",
    "                                    transform = transformer),\n",
    "                                    batch_size= 256,\n",
    "                                    shuffle= True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,\n",
    "                                    transform = transformer),\n",
    "                                    batch_size = 256,\n",
    "                                    shuffle = True\n",
    ")\n",
    "\n",
    "train_count = len(glob.glob(train_path+\"/**/*.jpg\"))\n",
    "test_count = len(glob.glob(test_path+\"/**/*.jpg\"))\n",
    "print(f\" Training Data: {train_count}, Testing Data: {test_count}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> buildings\n",
      " --> forest\n",
      " --> glacier\n",
      " --> mountain\n",
      " --> sea\n",
      " --> street\n"
     ]
    }
   ],
   "source": [
    "# Categories in the Dataset\n",
    "for catg in os.listdir(train_path):\n",
    "    print(f\" --> {catg}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_of_classes = 6):\n",
    "        super(ConvNet,self).__init__()\n",
    "\n",
    "        # output size after convolution => ((w-f+2P)/s)+1\n",
    "        # input shape of the batch = (256, 3, 150, 150) => (batch , depth , height , width)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,\n",
    "                               out_channels=12, #output channel is 12, this is depth\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "\n",
    "        # more features to the CNN algo\n",
    "        self.batch_normal_1 = nn.BatchNorm2d(num_features = 12) # output shape  => 256 , 12 , 150 , 150\n",
    "        self.relu_1 = nn.ReLU() # for non-linearity\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 2) # reduces convolutional output by factor of 2, new output shape  => 256 , 12 , 75 , 75\n",
    "\n",
    "        # 2nd Convolution block\n",
    "        self.conv2 = nn.Conv2d(in_channels=12,\n",
    "                               out_channels=20, # depth is 20\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "        # new output shape  => 256 , 20 , 75 , 75\n",
    "        self.batch_normal_2 = nn.BatchNorm2d(num_features = 20) # output shape  => 256 , 20 , 75 , 75\n",
    "        self.relu_2 = nn.ReLU() # for non-linearity\n",
    "\n",
    "        # 3rd Convolution block\n",
    "        self.conv3 = nn.Conv2d(in_channels=20,\n",
    "                               out_channels=32, # depth is 32\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1)\n",
    "        # new output shape  => 256 , 32 , 75 , 75\n",
    "        self.batch_normal_3 = nn.BatchNorm2d(num_features = 32) # output shape  => 256 , 32 , 75 , 75\n",
    "        self.relu_3 = nn.ReLU() # for non-linearity\n",
    "\n",
    "        # fully connected layer\n",
    "        self.fc = nn.Linear(in_features=32*75*75, out_features = num_of_classes)\n",
    "\n",
    "        # feed forward function\n",
    "    def forward(self,output):\n",
    "        output = self.conv1(output)\n",
    "        output = self.batch_normal_1(output)\n",
    "        output = self.relu_1(output)\n",
    "\n",
    "        output = self.max_pool(output)\n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.batch_normal_2(output)\n",
    "        output = self.relu_2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.batch_normal_3(output)\n",
    "        output = self.relu_3(output)\n",
    "\n",
    "        output = output.view(-1,32*75*75)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Model and tuning\n",
    "\n",
    "model = ConvNet(num_of_classes=6)\n",
    "optimizer = Adam(model.parameters(),lr=0.001,weight_decay=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "num_of_epochs = 30"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CHAT GPT DOCUMENTATION\n",
    "\n",
    "-> This code defines a CNN class called `ConvNet` that takes an input image and applies three convolutional layers with kernel size 3, stride 1 and padding 1.\n",
    "Then, it applies batch normalization, ReLU activation function, and max pooling for each convolutional layer.\n",
    "\n",
    "-> The input to the first convolutional layer is an image with 3 channels (RGB) and the output is 12 channels.\n",
    "The batch normalization is applied to the output of the first convolutional layer with 12 features. The ReLU activation function is applied to introduce non-linearity to the model.\n",
    "The max pooling reduces the size of the output by a factor of 2.\n",
    "\n",
    "-> Similarly, the second and third convolutional layers are applied, with 20 and 32 output channels, respectively.\n",
    "The batch normalization, ReLU activation function, and max pooling are applied to the output of each of these layers as well.\n",
    "\n",
    "Finally, the output of the third convolutional layer is reshaped and passed through a fully connected layer that has an output of `num_of_classes` neurons.\n",
    "\n",
    "-> After this, the model is defined, an optimizer, and a loss function are defined. The optimizer used is Adam with a learning rate of 0.001 and weight decay of 0.001.\n",
    " The loss function used is `nn.CrossEntropyLoss()`. The number of training epochs is set to 5.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 =====> Train Loss: 9.56 =====> Train Accuracy: 0.54 =====> Test Accuracy: 0.609\n",
      "Epoch: 1 =====> Train Loss: 1.29 =====> Train Accuracy: 0.72 =====> Test Accuracy: 0.622\n",
      "Epoch: 2 =====> Train Loss: 0.99 =====> Train Accuracy: 0.77 =====> Test Accuracy: 0.689\n",
      "Epoch: 3 =====> Train Loss: 0.70 =====> Train Accuracy: 0.83 =====> Test Accuracy: 0.624\n",
      "Epoch: 4 =====> Train Loss: 0.51 =====> Train Accuracy: 0.86 =====> Test Accuracy: 0.709\n",
      "Epoch: 5 =====> Train Loss: 0.37 =====> Train Accuracy: 0.90 =====> Test Accuracy: 0.754\n",
      "Epoch: 6 =====> Train Loss: 0.29 =====> Train Accuracy: 0.92 =====> Test Accuracy: 0.746\n",
      "Epoch: 7 =====> Train Loss: 0.26 =====> Train Accuracy: 0.93 =====> Test Accuracy: 0.738\n",
      "Epoch: 8 =====> Train Loss: 0.13 =====> Train Accuracy: 0.96 =====> Test Accuracy: 0.749\n",
      "Epoch: 9 =====> Train Loss: 0.09 =====> Train Accuracy: 0.97 =====> Test Accuracy: 0.743\n",
      "Epoch: 10 =====> Train Loss: 0.32 =====> Train Accuracy: 0.92 =====> Test Accuracy: 0.693\n",
      "Epoch: 11 =====> Train Loss: 0.26 =====> Train Accuracy: 0.94 =====> Test Accuracy: 0.699\n",
      "Epoch: 12 =====> Train Loss: 0.13 =====> Train Accuracy: 0.96 =====> Test Accuracy: 0.739\n",
      "Epoch: 13 =====> Train Loss: 0.07 =====> Train Accuracy: 0.98 =====> Test Accuracy: 0.755\n",
      "Epoch: 14 =====> Train Loss: 0.05 =====> Train Accuracy: 0.99 =====> Test Accuracy: 0.763\n",
      "Epoch: 15 =====> Train Loss: 0.04 =====> Train Accuracy: 0.99 =====> Test Accuracy: 0.761\n",
      "Epoch: 16 =====> Train Loss: 0.03 =====> Train Accuracy: 0.99 =====> Test Accuracy: 0.772\n",
      "Epoch: 17 =====> Train Loss: 0.03 =====> Train Accuracy: 0.99 =====> Test Accuracy: 0.781\n",
      "Epoch: 18 =====> Train Loss: 0.02 =====> Train Accuracy: 1.00 =====> Test Accuracy: 0.775\n",
      "Epoch: 19 =====> Train Loss: 0.02 =====> Train Accuracy: 0.99 =====> Test Accuracy: 0.711\n",
      "Epoch: 20 =====> Train Loss: 0.11 =====> Train Accuracy: 0.97 =====> Test Accuracy: 0.718\n",
      "Epoch: 21 =====> Train Loss: 0.16 =====> Train Accuracy: 0.96 =====> Test Accuracy: 0.746\n",
      "Epoch: 22 =====> Train Loss: 0.09 =====> Train Accuracy: 0.98 =====> Test Accuracy: 0.725\n",
      "Epoch: 23 =====> Train Loss: 0.04 =====> Train Accuracy: 0.99 =====> Test Accuracy: 0.761\n",
      "Epoch: 24 =====> Train Loss: 0.04 =====> Train Accuracy: 0.99 =====> Test Accuracy: 0.742\n",
      "Epoch: 25 =====> Train Loss: 0.03 =====> Train Accuracy: 0.99 =====> Test Accuracy: 0.741\n",
      "Epoch: 26 =====> Train Loss: 0.03 =====> Train Accuracy: 1.00 =====> Test Accuracy: 0.764\n",
      "Epoch: 27 =====> Train Loss: 0.02 =====> Train Accuracy: 1.00 =====> Test Accuracy: 0.762\n",
      "Epoch: 28 =====> Train Loss: 0.02 =====> Train Accuracy: 1.00 =====> Test Accuracy: 0.762\n",
      "Epoch: 29 =====> Train Loss: 0.02 =====> Train Accuracy: 1.00 =====> Test Accuracy: 0.778\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "for epoch in range(num_of_epochs):\n",
    "    # evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy = 0\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.cpu().data*images.size(0)\n",
    "        _,prediction = torch.max(outputs.data,1)\n",
    "\n",
    "        train_accuracy += int(torch.sum(prediction==labels.data))\n",
    "\n",
    "    train_accuracy /= train_count\n",
    "    train_loss /= train_count\n",
    "\n",
    "\n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    test_accuracy = 0\n",
    "\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "\n",
    "        outputs = model(images)\n",
    "        _,prediction = torch.max(outputs.data,1)\n",
    "        test_accuracy += int(torch.sum(prediction==labels.data))\n",
    "\n",
    "    test_accuracy /= test_count\n",
    "\n",
    "    print(f\"Epoch: {epoch} =====> Train Loss: {train_loss:.2f} =====> Train Accuracy: {train_accuracy:.2f} =====> Test Accuracy: {test_accuracy:.3f}\")\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "    torch.save(model.state_dict(), 'best_model.pth')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
